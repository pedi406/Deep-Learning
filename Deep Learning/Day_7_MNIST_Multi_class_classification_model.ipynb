{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Day 7: MNIST Multi-class classification model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JecJgLmCO5pq"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-XphER4SWG6"
      },
      "source": [
        "# Introduction\n",
        "In this notebook we will build a Neural Network multi-class classification model using a dataset popularly known as **'MNIST'**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcWWIvw2RxlS"
      },
      "source": [
        "# Agenda\n",
        "*  About the Data\n",
        "*  Loading Libraries\n",
        "*  Loading Data\n",
        "*  Basic EDA\n",
        "*  Data Preprocessing\n",
        "*  Model Building\n",
        "  *  Simple Neural Network With No Hidden Layer\n",
        "  *  Building Model Using Hidden Layer\n",
        "*  Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3x9Y9moS5fY"
      },
      "source": [
        "## About the Data\n",
        "**MNIST (Modified National Institute of Standards and Technology database)** is a large database of 70,000 handwritten digits. \n",
        "\n",
        "It has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST (National Institute of Standards and Technology).\n",
        "\n",
        "The objective here is to build a model that would recognize the correct digit that the given image is representing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8udR2dR1CAm"
      },
      "source": [
        "## Objective\n",
        "In this notebook we will classify handwritten digits using a simple neural network which has only input and output layers. We will then add a hidden layer and see how the performance of the model improves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y06TLJHMU_5x"
      },
      "source": [
        "## Loading Libraries\n",
        "All Python capabilities are not loaded to our working environment by default (even if they are already installed in your system). So, we import each and every library that we want to use. Sometimes we chose alias names for our libraries for the sake of our convenience for example we **import tensorflow as tf** and similarly the other libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6IzyeUHFlId"
      },
      "source": [
        "import tensorflow as tf                       # deep learning library\n",
        "import numpy as np                            # for matrix operations\n",
        "import matplotlib.pyplot as plt               # for visualization\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph7HLzWTFlIr"
      },
      "source": [
        "## Loading Data\n",
        "The MNIST dataset is available in the TensorFlow only. Let's load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubTJHv0xFlIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa99bd5-3e2f-4a55-8863-d989eccde36a"
      },
      "source": [
        "from tensorflow.keras.datasets.mnist import load_data    # To load the MNIST digit dataset\n",
        "\n",
        "(X_train, y_train) , (X_test, y_test) = load_data()      # Loading data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGVmx0ra2QLt"
      },
      "source": [
        "## Basic EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6WviKsE2Ism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018732fe-1737-49a8-b3df-a49c2d1898ca"
      },
      "source": [
        "print(\"There are \", len(X_train), \"images in the training dataset\")     # checking total number of records / data points available in the X_train dataset\n",
        "print(\"There are \", len(X_test), \"images in the test dataset\")     # checking total number of records / data points available in the X_test dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are  60000 images in the training dataset\n",
            "There are  10000 images in the test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12mEV-er2b7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ccb806f-a19e-4eb6-f04c-7d420a5bcca2"
      },
      "source": [
        "# Checking the shape of one image\n",
        "X_train[0].shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjJAlpfr296r"
      },
      "source": [
        "Each image in the dataset is of shape 28X28 numbers (i.e. pixels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZTMGFdy28lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d34f84-663e-4867-b4fe-80512184c8f8"
      },
      "source": [
        "# Take a look how one image looks like\n",
        "X_train[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMsn02nQ3TvA"
      },
      "source": [
        "Only numbers! Can't understand what digit does it represent. \n",
        "\n",
        "There is a function in matplotlib called as 'matshow()', it helps you to display the image of the array of numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDEEhHTt3Qsj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "7fe1ed37-0a4d-4355-8253-e689b07c56a5"
      },
      "source": [
        "plt.matshow(X_train[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7704dc0c50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovv623nJHbEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3704793-ae99-45c2-cbe2-4f3dbeb87151"
      },
      "source": [
        "# we can use y_train to cross check\n",
        "y_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LgYJdJV3-DN"
      },
      "source": [
        "Now one can easily say the above number is 5. Well we want to build a model that will tell you what digit does that 28X28 array represent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug3Tv0zpi5A0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "9ee36c5e-2569-4c69-a9ed-7939a456e9fd"
      },
      "source": [
        "# code to view the images\n",
        "num_rows, num_cols = 2, 5\n",
        "f, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n",
        "                     gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n",
        "                     squeeze=True)\n",
        "\n",
        "for r in range(num_rows):\n",
        "    for c in range(num_cols):\n",
        "      \n",
        "        image_index = r * 5 + c\n",
        "        ax[r,c].axis(\"off\")\n",
        "        ax[r,c].imshow( X_train[image_index], cmap='gray')\n",
        "        ax[r,c].set_title('No. %d' % y_train[image_index])\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR7nFyVY7UPU"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDX1gHtS44Y0"
      },
      "source": [
        "Let's normalize our data (i.e. both X_train and X_test). Normalization is a process that changes the range of pixel intensity values to the range 0 to 1.\n",
        "\n",
        "But why to normalize?\n",
        "\n",
        "The motivation to normalize is to achieve consistency in dynamic range for a set of data, signals, or images to avoid mental distraction and reduce the data redundancy. Also, normalizing the data can help you improve the model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYSYGzgr4fuG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e37247d9-63ed-4f90-a6ed-79169564cbdc"
      },
      "source": [
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "\"\"\"\n",
        "Why divided by 255?\n",
        "The pixel value lie in the range 0 - 255 representing the RGB (Red Green Blue) value. \"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWhy divided by 255?\\nThe pixel value lie in the range 0 - 255 representing the RGB (Red Green Blue) value. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHPqEcJT6xIx"
      },
      "source": [
        "Now if you look at the data, each pixel value should be in range 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGxTk0bM6lA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8817b528-d76e-4943-c50d-288f22547c8a"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
              "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
              "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
              "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
              "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
              "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
              "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
              "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
              "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
              "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
              "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
              "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
              "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
              "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
              "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
              "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwgjOLnw7Rl1"
      },
      "source": [
        "**Flatten the Data**\n",
        "\n",
        "We simply convert a 2 dimensional data (i.e. one image data) to 1 dimensional.\n",
        "\n",
        "Why to flatten data?\n",
        "\n",
        "Before understanding why let's check the shape of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krewjr8d60yL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a326649-da44-4de7-bb6a-748210c1930e"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCghTfZt89QE"
      },
      "source": [
        "The data is 3 dimensional. The first value i.e. 60000 is nothing but the number of records or images in this case. The second and third dimension represent each individual image i.e. each image is of shape 28X28. \n",
        "\n",
        "Most of the the supervised learning algorithms that execute classification and regression tasks, as well as some deep learning models built for this purposes, are fed with two-dimensional data. Since we have our data as three-dimensional, we will need to flatten our data to make it two-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTxiNjn287uw"
      },
      "source": [
        "X_train_flattened = X_train.reshape(len(X_train), 28*28)    # converting our 2D array representin an image to one dimensional\n",
        "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHF9he2FCMNG"
      },
      "source": [
        "Now if you check the shape of our data, it should be 2 dimensional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGA8LsPECJ9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1efb021-50a6-4041-efc3-4433789ff930"
      },
      "source": [
        "X_train_flattened.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k1BV6lDmYC-"
      },
      "source": [
        "**A sample example showing the conversion of 3D data to 2D**\n",
        "![3Dto2D](https://dphi-courses.s3.ap-south-1.amazonaws.com/Deep+Learning+Bootcamp/3D+to++2D.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rQqtuN5CY76"
      },
      "source": [
        "## Building Models\n",
        "### Very simple neural network with no hidden layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO6UMj04EI19"
      },
      "source": [
        "![simple neural network](https://dphi-courses.s3.ap-south-1.amazonaws.com/Deep+Learning+Bootcamp/mnist1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMJrUsyqFehV"
      },
      "source": [
        "**Define the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTFzdn5MCTeQ"
      },
      "source": [
        "# Defining the Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')     # The input shape is 784. \n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em_HXNMaF0AU"
      },
      "source": [
        "The activation function used here is 'sigmoid'. Do you recall why was it so from the [Binary Classification Notebook](https://github.com/dphi-official/Deep_Learning_Bootcamp/blob/master/DL%20For%20Classification/DL_Day6_Binary_Classification.ipynb)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEJSaVUlNlUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f48c30-3a4c-4055-c929-e03af416e6f4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGGoOmoVxr57"
      },
      "source": [
        "Generally for multi-class classification problem, it is suggested to use softmax. We tried both softmax activation and sigmoid activation, but sigmoid found to give better performance. You can also try using both and keep the one which gives better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns3xpXRxFhV6"
      },
      "source": [
        "**Compile the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w333bVueFdTZ"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFx4eplPGds9"
      },
      "source": [
        "*  **adam** is an optimization algorithm which is faster than Stochastic Gradient Descent. If you remember from the learning material of Day 4 (i.e. working of neural networks), we know that Stochastic Gradient Descent (SGD in short) is just a type of Gradient Descent algorithm.\n",
        "\n",
        "*  **sparse_categorical_crossentropy** is a loss function similar to **binary_crossentropy** (discussed in Binary Classification Notebook), the only difference is that if the target variable is binary we use binary_crossentropy but if your target values are normal integers more then two, use sparse categorical crossentropy. Why not use **categorical_crossentropy**? You may ask. Well, [this article](https://jovianlin.io/cat-crossentropy-vs-sparse-cat-crossentropy/) will help you understand it.\n",
        "\n",
        "*  The metrics used to evaluate the model is **accuracy**. Accuracy calculates how often the predictions calculated by the model are correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeSNBYcYJKNp"
      },
      "source": [
        "**Fit the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEhPuikwGaQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2e1cd8-a69e-4c2b-f8e9-60dead68c2df"
      },
      "source": [
        "model.fit(X_train_flattened, y_train, epochs=5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4712 - accuracy: 0.8758\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3043 - accuracy: 0.9150\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2835 - accuracy: 0.9202\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2731 - accuracy: 0.9242\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2666 - accuracy: 0.9255\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7700775190>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmIv3thYJYAD"
      },
      "source": [
        "You can play with different number of epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2LDdci5JdfE"
      },
      "source": [
        "**Evaluate the model on unseen data (i.e. X_test_flattened)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onu3n0QzJO1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6bc850d-46d6-4c26-c69e-874c9a8b8ba0"
      },
      "source": [
        "model.evaluate(X_test_flattened, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.2678 - accuracy: 0.9259\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2678122818470001, 0.9258999824523926]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT3uMdwaJuO9"
      },
      "source": [
        "The performance of the model on very simple model with no hidden layer is 92.6 %. Not Bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dmd6wUDJ8wU"
      },
      "source": [
        "**predict for the X_test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSPYvO3qJsmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787c9140-7935-4c91-9421-e610e8ef48c6"
      },
      "source": [
        "y_predicted = model.predict(X_test_flattened)\n",
        "y_predicted[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.5678605e-02, 4.3421588e-07, 8.5486203e-02, 9.5208740e-01,\n",
              "       2.1254122e-03, 1.2253848e-01, 1.3600165e-06, 9.9982125e-01,\n",
              "       1.4200458e-01, 6.5954256e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ6HhcLrKFfb"
      },
      "source": [
        "The above numbers are the probabilities values for different digits. The maximum probability will confirm what is the predicted digit for first image in X_test.\n",
        "\n",
        "The value at the 0th index in above array of numbers is saying the probability of the digit being 0. \n",
        "\n",
        "**Generalize:** The value at the nth index in above array of numbers is saying the probability of the digit being n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWeHXcDmKudF"
      },
      "source": [
        "**np.argmax finds a maximum element from an array and returns the index of it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ95EnDgKEnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12f1d80-ff25-4565-b609-3df90d087e2c"
      },
      "source": [
        "np.argmax(y_predicted[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYsBH4_VKy7z"
      },
      "source": [
        "The predicted digit is 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3LlzcSXLbw6"
      },
      "source": [
        "Let's see the original digit at first index in X_test. Can see this using matshow() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbaI7nX6KyIc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "0b7c5c59-c38c-41cc-832d-452c971f4c6c"
      },
      "source": [
        "plt.matshow(X_test[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f76fed890d0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOGElEQVR4nO3df6xf9V3H8ddr7e1lvS2uHaPWUqhjbJHNUcwdbAFNF2SyLaSQbbgmNjWZK1FIwCwqIVlook4k/BCdkhSp6xZgwxWEbHWuaaZIxI7SFFpaFMSirZdeoNOWAf359o97ild27+d7e7/f7znf2/fzkTTf7/e8z/ecd09vX/dzzvdzz3VECEBe72i6AQDNIgSA5AgBIDlCAEiOEACSIwSA5BoJAduX2f4X28/bvqGJHkps77K9zfZW25t7oJ81todtbx+1bK7tDbafqx7n9Fh/q2zvqY7hVtufarC/hbZ/YHuH7WdsX1ct74ljWOivlmPouucJ2J4m6V8lXSppt6QnJC2LiB21NlJge5ekwYh4peleJMn2L0l6TdLXI+JD1bJbJO2LiJurIJ0TEb/XQ/2tkvRaRNzaRE+j2Z4vaX5EbLE9W9KTkq6Q9OvqgWNY6O8q1XAMmxgJXCDp+Yh4ISIOSfqmpKUN9DFlRMSjkva9bfFSSWur52s18kXTiHH66xkRMRQRW6rnByTtlLRAPXIMC/3VookQWCDpP0e93q0a/8ITFJK+b/tJ2yubbmYc8yJiqHr+kqR5TTYzjmttP12dLjR2ujKa7UWSzpe0ST14DN/Wn1TDMeTC4NgujohfkPRJSddUw92eFSPndL02//suSWdLWixpSNJtzbYj2Z4laZ2k6yNi/+haLxzDMfqr5Rg2EQJ7JC0c9fqMalnPiIg91eOwpIc0cgrTa/ZW55LHzymHG+7n/4mIvRFxNCKOSbpbDR9D230a+Q92b0Q8WC3umWM4Vn91HcMmQuAJSefY/lnbMyR9XtIjDfQxJtsD1cUZ2R6Q9AlJ28vvasQjklZUz1dIerjBXn7C8f9clSvV4DG0bUn3SNoZEbePKvXEMRyvv7qOYe2fDkhS9VHHn0iaJmlNRPxh7U2Mw/Z7NfLdX5KmS7qv6f5s3y9piaTTJO2VdJOkv5H0gKQzJb0o6aqIaOTi3Dj9LdHIMDYk7ZJ09ajz77r7u1jSP0raJulYtfhGjZx3N34MC/0tUw3HsJEQANA7uDAIJEcIAMkRAkByhACQHCEAJNdoCPTwlFxJ9NeuXu6vl3uT6u2v6ZFAT/9DiP7a1cv99XJvUo39NR0CABrW1mQh25dJulMjM//+MiJuLq0/w/1xigbeen1YB9Wn/knvv9vorz293F8v9yZ1vr839WMdioMeqzbpEJjMzUFO9dy40JdMan8AJm9TbNT+2DdmCLRzOsDNQYCTQDshMBVuDgKghend3kH1UcdKSTpFM7u9OwAnqJ2RwIRuDhIRqyNiMCIGe/lCDJBVOyHQ0zcHATAxkz4diIgjtq+V9Hf6v5uDPNOxzgDUoq1rAhGxXtL6DvUCoAHMGASSIwSA5AgBIDlCAEiOEACSIwSA5AgBIDlCAEiOEACSIwSA5AgBIDlCAEiOEACSIwSA5AgBIDlCAEiOEACSIwSA5AgBIDlCAEiOEACSIwSA5AgBIDlCAEiOEACSIwSA5AgBIDlCAEiOEACSIwSA5AgBILnp7bzZ9i5JByQdlXQkIgY70RSA+rQVApWPR8QrHdgOgAZwOgAk124IhKTv237S9spONASgXu2eDlwcEXtsny5pg+1nI+LR0StU4bBSkk7RzDZ3B6DT2hoJRMSe6nFY0kOSLhhjndURMRgRg33qb2d3ALpg0iFge8D27OPPJX1C0vZONQagHu2cDsyT9JDt49u5LyK+15GuANRm0iEQES9IOq+DvQBoAB8RAskRAkByhACQHCEAJEcIAMkRAkBynfgpwjRe/eLHivUzlz9frD87PK9YP3Swr1hfcH+5PnP3a8X6sa07inXkxEgASI4QAJIjBIDkCAEgOUIASI4QAJIjBIDkmCdwAn73d+4r1j8z8KPyBs5us4El5fKuI68X63e+/PE2G5jafjh8VrE+cNtPFevTNz7ZyXZ6BiMBIDlCAEiOEACSIwSA5AgBIDlCAEiOEACSc0TUtrNTPTcu9CW17a/TfvzZC4v1Vz5cztQ5O8vH+kc/52J9xof/u1i/5UMPFuuXvvONYv27r88q1j89s3y/gna9EYeK9U0HB4r1Jaccbmv/7/vu1cX6+1c+0db2m7QpNmp/7BvzC4yRAJAcIQAkRwgAyRECQHKEAJAcIQAkRwgAyXE/gRMw8O1NLertbf/U9t6uP/vpJcX6H1y0qLz/fyj/3oRblrzvBDs6MdPfOFasDzw9VKy/+9F1xfrPz2jxext2lesnq5YjAdtrbA/b3j5q2VzbG2w/Vz3O6W6bALplIqcDX5N02duW3SBpY0ScI2lj9RrAFNQyBCLiUUn73rZ4qaS11fO1kq7ocF8AajLZC4PzIuL4CdpLksq/ZA9Az2r704EY+QmkcX8yxvZK25ttbz6sg+3uDkCHTTYE9tqeL0nV4/B4K0bE6ogYjIjBPvVPcncAumWyIfCIpBXV8xWSHu5MOwDq1nKegO37NXLH+9Ns75Z0k6SbJT1g+wuSXpR0VTebxMQceWlvsT6wrlw/2mL7A99+9QQ76qy9v/GxYv2DM8pfzrfu+0CxvuivXijWjxSrU1fLEIiIZeOUpu7dQQC8hWnDQHKEAJAcIQAkRwgAyRECQHKEAJAc9xNAz5h+1sJi/as3frVY7/O0Yv2v7/zlYv3dQ48X6ycrRgJAcoQAkBwhACRHCADJEQJAcoQAkBwhACTHPAH0jGd/e0Gx/pF+F+vPHHqjWJ+74/UT7ikDRgJAcoQAkBwhACRHCADJEQJAcoQAkBwhACTHPAHU5uCnP1Ksb/nsHS22UP4NVr953XXF+jv/6Ycttp8TIwEgOUIASI4QAJIjBIDkCAEgOUIASI4QAJJjngBq8x+fLH/PmeXyPIBl/35psT7ze08V61Gs5tVyJGB7je1h29tHLVtle4/trdWfT3W3TQDdMpHTga9JumyM5XdExOLqz/rOtgWgLi1DICIelbSvhl4ANKCdC4PX2n66Ol2Y07GOANRqsiFwl6SzJS2WNCTptvFWtL3S9mbbmw/r4CR3B6BbJhUCEbE3Io5GxDFJd0u6oLDu6ogYjIjBvhY/BQagfpMKAdvzR728UtL28dYF0NtazhOwfb+kJZJOs71b0k2SltherJGPXndJurqLPWKKeMfs2cX68l98rFjff+zNYn34K+8t1vsPPlGsY2wtQyAilo2x+J4u9AKgAUwbBpIjBIDkCAEgOUIASI4QAJIjBIDkuJ8AOua5VR8s1r9z2l8U60uf+0yx3r+eeQDdwEgASI4QAJIjBIDkCAEgOUIASI4QAJIjBIDkmCeACfufX/tosf70r/5psf5vRw4X66/98RnFer+GinVMDiMBIDlCAEiOEACSIwSA5AgBIDlCAEiOEACSY54A3jJ9wc8U69d/+VvFer/LX06ff2p5sf6ev+V+AU1gJAAkRwgAyRECQHKEAJAcIQAkRwgAyRECQHLME0jE08v/3Od9Z3ex/rlZrxbr9x44vVif9+Xy95xjxSq6peVIwPZC2z+wvcP2M7avq5bPtb3B9nPV45zutwug0yZyOnBE0pci4lxJH5V0je1zJd0gaWNEnCNpY/UawBTTMgQiYigitlTPD0jaKWmBpKWS1larrZV0RbeaBNA9J3Rh0PYiSedL2iRpXkQcv+nbS5LmdbQzALWYcAjYniVpnaTrI2L/6FpEhKQY530rbW+2vfmwDrbVLIDOm1AI2O7TSADcGxEPVov32p5f1edLGh7rvRGxOiIGI2KwT/2d6BlAB03k0wFLukfSzoi4fVTpEUkrqucrJD3c+fYAdNtE5glcJGm5pG22t1bLbpR0s6QHbH9B0ouSrupOi+iY8z5QLP/+6d9oa/N//pXPFevveurxtraP7mgZAhHxmCSPU76ks+0AqBvThoHkCAEgOUIASI4QAJIjBIDkCAEgOe4ncBKZdu77i/WV32xvPte5a64p1hd945/b2j6awUgASI4QAJIjBIDkCAEgOUIASI4QAJIjBIDkmCdwEnn2t8p3fb985v5ivZUz/v5QeYUY8w5z6HGMBIDkCAEgOUIASI4QAJIjBIDkCAEgOUIASI55AlPIm5dfUKxvvPy2FluY2blmcNJgJAAkRwgAyRECQHKEAJAcIQAkRwgAyRECQHIt5wnYXijp65LmSQpJqyPiTturJH1R0svVqjdGxPpuNQrpvy6aVqyfOb29eQD3Hji9WO/bX76fAHcTmJomMlnoiKQvRcQW27MlPWl7Q1W7IyJu7V57ALqtZQhExJCkoer5Ads7JS3odmMA6nFC1wRsL5J0vqRN1aJrbT9te43t8r2tAPSkCYeA7VmS1km6PiL2S7pL0tmSFmtkpDDmxHXbK21vtr35sA52oGUAnTShELDdp5EAuDciHpSkiNgbEUcj4pikuyWN+dMtEbE6IgYjYrBP/Z3qG0CHtAwB25Z0j6SdEXH7qOXzR612paTtnW8PQLdN5NOBiyQtl7TN9tZq2Y2SltlerJFPhnZJurorHQLoqol8OvCYJI9RYk7AFPNHr55brD/+K4uK9Rja1sFu0CuYMQgkRwgAyRECQHKEAJAcIQAkRwgAyRECQHKOGn+n/KmeGxf6ktr2B2DEptio/bFvrPk+jASA7AgBIDlCAEiOEACSIwSA5AgBIDlCAEiu1nkCtl+W9OKoRadJeqW2Bk4c/bWnl/vr5d6kzvd3VkS8Z6xCrSHwEzu3N0fEYGMNtEB/7enl/nq5N6ne/jgdAJIjBIDkmg6B1Q3vvxX6a08v99fLvUk19tfoNQEAzWt6JACgYYQAkBwhACRHCADJEQJAcv8LId/VeNhqNOUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qym97msLLr9A"
      },
      "source": [
        "Hence the prediction is correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIGCWjGtLzPj"
      },
      "source": [
        "### Building Neural Network Model Using hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-tS8rVaLqwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b479a35-d4ce-46a8-c1a4-8c93fb5c6ed5"
      },
      "source": [
        "# Defining the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n",
        "    tf.keras.layers.Dense(100, input_shape=(100,),activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "model.summary()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89,610\n",
            "Trainable params: 89,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff-aZb_RN0qD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670c1932-3f85-4eee-900f-4184d2b2c453"
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train_flattened, y_train, batch_size= 128,epochs=5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3386 - accuracy: 0.9027\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1381 - accuracy: 0.9584\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0971 - accuracy: 0.9713\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9772\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0584 - accuracy: 0.9825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f770064b410>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thtxdz9mM4hG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57297065-0d9c-4c8d-e5a2-6f855480b323"
      },
      "source": [
        "# Evaluate the model\n",
        "model.evaluate(X_test_flattened,y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9738\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08590240776538849, 0.973800003528595]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57Mi2yePNGmb"
      },
      "source": [
        "**Try yourself**: \n",
        "Change the values of epochs and try adding more hidden layers. Are you able to increase the accuracy above 97.5%?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QQyh13YlL-X"
      },
      "source": [
        "# Saving and loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ihfjL2GlGAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcd0487-cffd-46a4-84eb-f7b48f977d17"
      },
      "source": [
        "# saving the model\n",
        "save_dir = \"/results/\"\n",
        "model_name = 'keras_mnist.h5'\n",
        "model.save(model_name)\n",
        "model_path = save_dir + model_name\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved trained model at /results/keras_mnist.h5 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F91VHEpJONIF"
      },
      "source": [
        "# Summary\n",
        "*  We learned why we need to normalize and flatten the data.\n",
        "*  We observed the performance of very simple neural network with no hidden layer and that of with one hidden layer with 100 hidden neurons. The performance of later model was better than earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JecJgLmCO5pq"
      },
      "source": [
        "### **Reference**\n",
        "[Neural Network For Handwritten Digits Classification](https://www.youtube.com/watch?v=iqQgED9vV7k&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7vYNxsJPSsc"
      },
      "source": [
        "# **Exercises**\n",
        "*  Try different optimizers and losses in the above models and check the performance of the models.\n",
        "  *  [Different losses that can be used](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
        "  *  [Different optimizers that can be used](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)"
      ]
    }
  ]
}